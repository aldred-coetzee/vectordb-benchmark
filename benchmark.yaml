# Shared Benchmark Configuration
# This file defines datasets, index types, and search parameters for all databases

# =============================================================================
# Datasets
# =============================================================================

datasets:
  sift:
    path: data/sift
    vectors: 1000000
    dimensions: 128
    metric: L2
    format: fvecs
    name: "SIFT-1M"
    source: "ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz"
    purpose: "Baseline — the standard ANN benchmark. Low dimension (128D), L2 distance. Allows direct comparison with published results from other benchmarking tools."
    description: "1M SIFT image descriptors extracted from the Flickr dataset. 128-dimensional local feature vectors widely used as the canonical vector search benchmark since 2008."

  gist:
    path: data/gist
    vectors: 1000000
    dimensions: 960
    metric: L2
    format: fvecs
    name: "GIST-1M"
    source: "ftp://ftp.irisa.fr/local/texmex/corpus/gist.tar.gz"
    purpose: "Dimension stress — 960D vectors test memory bandwidth, cache pressure, and curse-of-dimensionality effects. Exposes database payload limits."
    description: "1M GIST global image descriptors. 960-dimensional vectors — 7.5x larger than SIFT — that stress high-dimensional indexing."

  glove-100:
    path: data/glove-100/glove-100-angular.hdf5
    vectors: 1183514
    dimensions: 100
    metric: cosine
    format: hdf5
    name: "GloVe-100"
    source: "http://ann-benchmarks.com/glove-100-angular.hdf5"
    purpose: "Cosine metric — most production vector search workloads use cosine or inner-product distance, not L2. Tests native angular distance support and whether databases incur overhead converting between metrics."
    description: "1.18M GloVe word embedding vectors (100D) trained on Wikipedia + Gigaword. Angular (cosine) distance. The standard dataset for testing non-L2 metrics in ANN benchmarks."

  dbpedia-openai:
    path: data/dbpedia-openai/dbpedia-openai-1000k-angular.hdf5
    vectors: 990000
    dimensions: 1536
    metric: cosine
    format: hdf5
    name: "DBpedia-OpenAI-1M"
    source: "https://storage.googleapis.com/ann-datasets/ann-benchmarks/dbpedia-openai-1000k-angular.hdf5"
    purpose: "Production-representative — 1536D OpenAI text-embedding-ada-002 vectors match the dimensionality of the most widely deployed embedding model. Tests real-world RAG/search workload performance at high dimensionality with cosine distance."
    description: "990K DBpedia entity embeddings generated with OpenAI text-embedding-ada-002 (1536D). Angular (cosine) distance. Represents production RAG and semantic search workloads."

  # Dev datasets — small subsets for fast iteration (NOT for benchmarking)
  # Generate with: python scripts/generate_dev_datasets.py
  sift-dev:
    path: data/sift-dev
    vectors: 10000
    dimensions: 128
    metric: L2
    format: fvecs
    name: "SIFT-dev"
    description: "Dev subset of SIFT-1M (10K vectors, 100 queries). For code testing only."

  gist-dev:
    path: data/gist-dev
    vectors: 10000
    dimensions: 960
    metric: L2
    format: fvecs
    name: "GIST-dev"
    description: "Dev subset of GIST-1M (10K vectors, 100 queries). For code testing only."

# =============================================================================
# Index Types
# =============================================================================

indexes:
  flat:
    description: "Brute-force exact search. Compares the query against every vector in the dataset. Guarantees 100% recall but is slow on large datasets. Used as a baseline to validate recall and measure raw scan throughput."
    params: {}

  hnsw:
    description: "Hierarchical Navigable Small World graph — the dominant approximate nearest neighbor (ANN) index. Builds a multi-layer proximity graph at ingest time, then traverses it at search time. Trades recall for speed: higher efSearch improves recall but reduces QPS."
    M: 48
    efConstruction: 200
    efSearch:
      - 128
      - 256
      - 512

  ivf:
    description: "Inverted File index. Partitions vectors into clusters and searches only nearby clusters. Not yet implemented."
    params: {}

  ivfpq:
    description: "IVF with Product Quantization. Combines cluster-based partitioning with vector compression for memory efficiency. Not yet implemented."
    params: {}

# =============================================================================
# Known Exclusions
# =============================================================================
# Database+dataset combinations that are excluded from the benchmark run.
# These are surfaced in the generated report with reasons.

exclusions:
  - database: milvus
    dataset: dbpedia-openai
    reason: "Container ran out of disk space during search at M=16/efC=64. Milvus writes search cache to /var/lib/milvus/data/cache/ which exceeded container filesystem limits with 1536D vectors."
  - database: milvus
    dataset: gist
    reason: "Container crashed (OOM) during search at M=16/efC=64. Ingest succeeded (30.6GB peak memory) but Milvus process was killed before search completed."

# Caveats — database+dataset combinations that run but with known limitations.
# These are surfaced in the report alongside exclusions.
caveats:
  - database: kdbai
    dataset: all
    note: "Running with mmapLevel=1 (memory-mapped vectors). mmapLevel=0 (fully in-memory) OOM'd on DBpedia-OpenAI at M=16/efC=64 with 64GB container limit. mmapLevel=1 may reduce recall by 5-14% compared to fully in-memory operation."

# =============================================================================
# Search Configuration
# =============================================================================

search:
  k: 10
  num_queries: 10000
  warmup: 100
  batch_size: 50000

# =============================================================================
# Metric Descriptions (used in report generation)
# =============================================================================

metrics:
  qps:
    name: "Queries Per Second (QPS)"
    description: "Number of single-vector queries completed per second. Queries are executed sequentially (one at a time, wait for response). Measures single-client throughput, not concurrent load."

  recall_at_10:
    name: "Recall@10"
    description: "Fraction of true 10 nearest neighbors found by the search. Computed against brute-force ground truth provided with each dataset. 1.0 = perfect accuracy."

  recall_at_100:
    name: "Recall@100"
    description: "Fraction of true 100 nearest neighbors found. A stricter accuracy measure than Recall@10."

  latency_p50:
    name: "P50 Latency (ms)"
    description: "Median query latency. 50% of queries complete faster than this value."

  latency_p99:
    name: "P99 Latency (ms)"
    description: "99th percentile query latency. Measures tail latency — the worst-case experience for 1 in 100 queries."

  ingest_throughput:
    name: "Ingest Throughput (vectors/sec)"
    description: "Rate of vector insertion including index building. For HNSW, each insert updates the graph, so throughput decreases as the dataset grows."

  batch_qps:
    name: "Batch QPS"
    description: "Queries per second when all queries are sent in a single API call. Measures throughput under batch workloads. Available for 5/9 databases (FAISS, Qdrant, Milvus, ChromaDB, KDB.AI). Per-query latency percentiles are not available — the database processes queries together."

  ef_search:
    name: "efSearch"
    description: "HNSW search beam width — the number of candidate nodes evaluated at each step of graph traversal. Higher values explore more of the graph, improving recall at the cost of QPS. Swept across [128, 256, 512] to produce a recall-vs-speed tradeoff curve."

  m_parameter:
    name: "M (HNSW)"
    description: "Maximum number of edges per node in the HNSW graph. Fixed at M=48 across all databases for fair comparison. Higher M improves recall and increases memory usage."

  ef_construction:
    name: "efConstruction (HNSW)"
    description: "Beam width used during HNSW graph construction. Fixed at 200 across all databases. Higher values build a better quality graph at the cost of slower ingest."

# =============================================================================
# Infrastructure
# =============================================================================

infrastructure:
  repo: "https://github.com/aldred-coetzee/vectordb-benchmark"
  aws:
    region: us-west-2
    os: "Amazon Linux 2023"
    orchestrator:
      instance_type: t3.small
      vcpus: 2
      memory_gb: 2
      role: "Launches worker instances, monitors progress via S3 heartbeats, aggregates results, generates report. Does not run any benchmarks."
    worker:
      instance_type: m5.4xlarge
