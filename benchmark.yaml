# Shared Benchmark Configuration
# This file defines datasets, index types, and search parameters for all databases

# =============================================================================
# Datasets
# =============================================================================

datasets:
  sift:
    path: data/sift
    vectors: 1000000
    dimensions: 128
    description: "SIFT-1M: 1M image descriptors, 128D. Baseline benchmark — moderate dimensionality, well-studied."

  gist:
    path: data/gist
    vectors: 1000000
    dimensions: 960
    description: "GIST-1M: 1M image descriptors, 960D. High-dimension stress test — exposes payload limits and curse of dimensionality."

  # Dev datasets — small subsets for fast iteration (NOT for benchmarking)
  # Generate with: python scripts/generate_dev_datasets.py
  sift-dev:
    path: data/sift-dev
    vectors: 10000
    dimensions: 128
    description: "Dev subset of SIFT-1M (10K vectors, 100 queries). For code testing only."

  gist-dev:
    path: data/gist-dev
    vectors: 10000
    dimensions: 960
    description: "Dev subset of GIST-1M (10K vectors, 100 queries). For code testing only."

# =============================================================================
# Index Types
# =============================================================================

indexes:
  flat:
    description: "Brute-force exact search. Compares the query against every vector in the dataset. Guarantees 100% recall but is slow on large datasets. Used as a baseline to validate recall and measure raw scan throughput."
    params: {}

  hnsw:
    description: "Hierarchical Navigable Small World graph — the dominant approximate nearest neighbor (ANN) index. Builds a multi-layer proximity graph at ingest time, then traverses it at search time. Trades recall for speed: higher efSearch improves recall but reduces QPS."
    M: 16
    efConstruction: 64
    efSearch:
      - 32
      - 64
      - 128
      - 256

  ivf:
    description: "Inverted File index. Partitions vectors into clusters and searches only nearby clusters. Not yet implemented."
    params: {}

  ivfpq:
    description: "IVF with Product Quantization. Combines cluster-based partitioning with vector compression for memory efficiency. Not yet implemented."
    params: {}

# =============================================================================
# Search Configuration
# =============================================================================

search:
  k: 10
  num_queries: 10000
  warmup: 100
  batch_size: 50000

# =============================================================================
# Metric Descriptions (used in report generation)
# =============================================================================

metrics:
  qps:
    name: "Queries Per Second (QPS)"
    description: "Number of single-vector queries completed per second. Queries are executed sequentially (one at a time, wait for response). Measures single-client throughput, not concurrent load."

  recall_at_10:
    name: "Recall@10"
    description: "Fraction of true 10 nearest neighbors found by the search. Computed against brute-force ground truth provided with each dataset. 1.0 = perfect accuracy."

  recall_at_100:
    name: "Recall@100"
    description: "Fraction of true 100 nearest neighbors found. A stricter accuracy measure than Recall@10."

  latency_p50:
    name: "P50 Latency (ms)"
    description: "Median query latency. 50% of queries complete faster than this value."

  latency_p99:
    name: "P99 Latency (ms)"
    description: "99th percentile query latency. Measures tail latency — the worst-case experience for 1 in 100 queries."

  ingest_throughput:
    name: "Ingest Throughput (vectors/sec)"
    description: "Rate of vector insertion including index building. For HNSW, each insert updates the graph, so throughput decreases as the dataset grows."

  ef_search:
    name: "efSearch"
    description: "HNSW search beam width — the number of candidate nodes evaluated at each step of graph traversal. Higher values explore more of the graph, improving recall at the cost of QPS. Swept across [32, 64, 128, 256] to produce a recall-vs-speed tradeoff curve."

  m_parameter:
    name: "M (HNSW)"
    description: "Maximum number of edges per node in the HNSW graph. Fixed at M=16 across all databases for fair comparison. Higher M improves recall and increases memory usage."

  ef_construction:
    name: "efConstruction (HNSW)"
    description: "Beam width used during HNSW graph construction. Fixed at 64 across all databases. Higher values build a better quality graph at the cost of slower ingest."
